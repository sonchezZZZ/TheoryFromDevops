The instance is running inside a Docker container on your node.

Pods that are running inside Kubernetes are running on a private, isolated network. By default they are visible from other pods and services within the same kubernetes cluster, but not outside that network. When we use kubectl, we're interacting through an API endpoint to communicate with our application.

We will cover other options on how to expose your application outside the kubernetes cluster

Под — это абстрактный объект Kubernetes, представляющий собой группу из одного или нескольких контейнеров приложения (например, Docker или rkt) и совместно используемых ресурсов для этих контейнеров. Ресурсами могут быть:

Общее хранилище (тома)
Сеть (уникальный IP-адрес кластера)
Информация по выполнению каждого контейнера (версия образа контейнера или используемые номера портов)

Под представляет специфичный для приложения "логический хост" и может содержать разные контейнеры приложений, которые в общем и целом тесно связаны. Например, в поде может размещаться как контейнер с приложением на Node.js, так и другой контейнер, который использует данные от веб-сервера Node.js. Все контейнеры в поде имеют одни и те же IP-адрес и пространство порта, выполняющиеся в общем контексте на одном и том же узле.

Поды — неделимая единица в платформе Kubernetes. При создании развёртывания в Kubernetes, создаются поды с контейнерами внутри (в отличие от непосредственного создания контейнеров). Каждый Pod-объект связан с узлом, на котором он размещён, и остаётся там до окончания работы (согласно стратегии перезапуска) либо удаления. В случае неисправности узла такой же под будет распределён на другие доступные узлы в кластере

# Узлы
Под всегда работает в узле. 

**Узел** — это рабочая машина в Kubernetes, которая в зависимости от кластера может быть либо виртуальной, либо физической. Каждый узел управляется **мастером** (ведущим узлом). Узел может содержать несколько подов, которые мастер Kubernetes автоматически размещает на разные узлы кластера. Ведущий узел при автоматическом планировании (распределении подов по узлам) учитывает доступные ресурсы на каждом узле.

В каждом узле Kubernetes как минимум работает:

- **Kubelet** — процесс, отвечающий за взаимодействие между мастером Kubernetes и узлом; он управляет подами и запущенными контейнерами на рабочей машине.
- Среда выполнения контейнера (например, Docker или rkt), отвечающая за получение (загрузку) образа контейнера из реестра, распаковку контейнера и запуск приложения.

![image](https://user-images.githubusercontent.com/79608549/152444351-2cb0ac5b-85e5-489a-bcfe-1af89091fc4d.png)

### Диагностика с помощью kubectl
В модуле 2 вы использовали инструмент командной строки Kubectl. В этом (третьем) модуле вы продолжите его использовать, но для получения информации о развернутых приложениях и окружениях, в которых они работают. Наиболее распространенные операции выполняются с использованием следующих команд kubectl:

- ``kubectl get`` — вывод списка ресурсов
- ``kubectl describe`` — вывод подробной информации о ресурсе
- kubectl logs — вывод логов контейнера в поде
- kubectl exec — выполнение команды в контейнере пода
- Перечисленные выше команды можно использовать, чтобы узнать, когда и где приложения были развернуты, их текущее состояние и конфигурацию.


**Сервис в Kubernetes** — это абстрактный объект, который определяет логический набор подов и политику доступа к ним. Сервисы создают слабую связь между подами, которые от них зависят. Сервис создаётся в формате YAML (рекомендуемый формат) или JSON, как и все остальные объекты в Kubernetes. Как правило, набор подов для сервиса определяется LabelSelector (ниже описано, в каких случаях понадобиться сервис без указания selector в спецификации).

Хотя у каждого пода есть уникальный IP-адрес, эти IP-адреса не доступны за пределами кластера без использования сервиса. Сервисы позволяют приложениям принимать трафик. Сервисы могут быть по-разному открыты, в зависимости от указанного поля type в ServiceSpec:

- **ClusterIP** (по умолчанию) - открывает доступ к сервису по внутреннему IP-адресу в кластере. Этот тип делает сервис доступным только внутри кластера.
-
- **NodePort** - открывает сервис на одном и том же порту каждого выбранного узла в кластере с помощью NAT. Делает сервис доступным вне кластера, используя NodeIP NodePort. Является надмножеством ClusterIP.
  
-**LoadBalancer** - создает внешний балансировщик нагрузки в текущем облаке (если это поддерживается) и назначает фиксированный внешний IP-адрес для сервиса. Является надмножеством NodePort.
- **ExternalName** - открывает доступ к сервису с указанным именем (определённое в поле externalName в спецификации) и возвращает запись CNAME. Прокси не используется. Для этого типа требуется версия kube-dns 1.7 или выше.

## Services

При создании Service, приложение доступно по:

- **Cluster IP** - внутри кластера
- **NodePort** - порт на всех Worker нодах
- **External name** - DNS CNAME Record
- **Load Balancer** - в CLoud Clusters(AWS)

## Control Plane
Управляющий уровень Kubernetes состоит из 4-х объектов, которые расположены на Мастер-Нодах. Для отказоустойчивости кластера рекомендуем соблюдать кворум Мастеров например, 3 Мастер-Ноды.

![image](https://user-images.githubusercontent.com/79608549/209569662-364a7f24-27e4-4e1b-8f88-64e8ed67ba0c.png)

## Data Plane
Компонентами на Воркер-Нодах являются runtime, kubelet и kube-proxy.

kubelet - отвечает за работу контейнеров в Поде. Бывают ситуации, когда Ваш Контейнер в Поде рестартовал, а причину не дают ни логи, ни describe, так вот, kubelet - всему Голова, зайдите по ssh на Ноду с проблемным Подом и выполните команду sudo journalctl -u kubelet | grep <podname> я уверен, Вы найдете причину.
  
**kube-proxy** - нужен для настройки сетевого трафика в Подах, он частично реализует концепцию Сервиса. kube-proxy конфигурирует правила сети на узлах. При помощи них разрешаются сетевые подключения к вашим подам изнутри и снаружи кластера.

**runtime** - это программа, предназначенная для выполнения контейнеров (Docker, CRIO, ... )

Все дороги ведут в apiserver

Используя утилиту kubectl вы общаетесь с Кластером через kube-apiserver. Он предоставляет API Kubernetes.

**scheduler** следит за Подами не распределенными на Воркер-Ноду, он выбирает им подходящую Ноду по множеству критериев.

kube-controller-manager запускает контроллеры, которые подписываются в ApiServer на свой ресурс.

etcd - это key-value хранилище, в котором находится вся информация о состоянии Кубернетес в текущий момент. Кубернетес кластер можно полностью восстановить, имея резервную копию etcd.
  
## Ingress Controller

![image](https://user-images.githubusercontent.com/79608549/152692227-2c82ddc5-7061-463a-8aeb-d98a22bb7759.png)

- set from github

